# -*- coding: utf-8 -*-
"""softComputing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T0do9Cy1ea2KdOiba0AcwT6jWm7vPglp
"""

!pip install -q kaggle

from google.colab import files

files.upload()

!mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d bachrr/covid-chest-xray

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

!cd /content
!ls

!mkdir -p input/covid-chest-xray
!mkdir -p input/chest-xray-pneumonia

!rm -rf dataset
!mkdir -p dataset/covid
!mkdir -p dataset/normal

!unzip covid-chest-xray.zip -d input/covid-chest-xray

!unzip chest-xray-pneumonia.zip -d input/chest-xray-pneumonia

!pip install imutils

from keras import backend as K
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from imutils import paths
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import random
import shutil
import cv2
import os

import warnings
warnings.filterwarnings("ignore")

dataset_path='./dataset'

"""Covid X-ray"""
samples = 141
covid_dataset_path = '../content/input/covid-chest-xray'
csvPath = os.path.sep.join([covid_dataset_path, "metadata.csv"])
df = pd.read_csv(csvPath)
for (i, row) in df.iterrows():
  if row["finding"] != "COVID-19" or row["view"] != "PA":
    continue
  imagePath = os.path.sep.join([covid_dataset_path, "images", row["filename"]])
  if not os.path.exists(imagePath):
    continue
  filename = row["filename"].split(os.path.sep)[-1]
  outputPath = os.path.sep.join([f"{dataset_path}/covid", filename])
  shutil.copy2(imagePath, outputPath)

"""Normal X-ray dataset"""
pneumonia_dataset_path ='../content/input/chest-xray-pneumonia/chest_xray'
basePath = os.path.sep.join([pneumonia_dataset_path, "train", "NORMAL"])
imagePaths = list(paths.list_images(basePath))
print(len(imagePaths))
random.seed(42)
random.shuffle(imagePaths)
imagePaths = imagePaths[:samples]
for (i, imagePath) in enumerate(imagePaths):
  filename = imagePath.split(os.path.sep)[-1]
  outputPath = os.path.sep.join([f"{dataset_path}/normal", filename])
  shutil.copy2(imagePath, outputPath)

covid_dataset=pd.read_csv("../content/input/covid-chest-xray/metadata.csv")
covid_dataset.head()

# function to plot images in a grid
def ceildiv(a, b):
  return -(-a // b)

def plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):
  """Plot the images in a grid"""
  f = plt.figure(figsize=figsize)
  if maintitle is not None: plt.suptitle(maintitle, fontsize=10)
  for i in range(len(imspaths)):
    sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)
    sp.axis('off')
    if titles is not None: sp.set_title(titles[i], fontsize=16)
    img = plt.imread(imspaths[i])
    plt.imshow(img)

normal_images = list(paths.list_images(f"{dataset_path}/normal"))
covid_images = list(paths.list_images(f"{dataset_path}/covid"))

print("Normal cases :",len(normal_images))
print("Covid cases :",len(covid_images))

plots_from_files(normal_images, rows=5, maintitle="Normal X-ray images")
plots_from_files(covid_images, rows=5, maintitle="Covid-19 X-ray images")

#learning rate, epoch and batch size
INIT_LR = 1e-3
EPOCHS = 15
BS = 8

class_to_label_map = {'covid' : 1, 'normal' : 0}

imagePaths = list(paths.list_images(dataset_path))
data = []
labels = []
for imagePath in imagePaths:
  label = imagePath.split(os.path.sep)[-2]
  image = cv2.imread(imagePath)
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  image = cv2.resize(image, (224, 224))
  data.append(image)
  labels.append(class_to_label_map[label])
data = np.array(data) / 255.0
labels = np.array(labels)

labels.shape
labels = to_categorical(labels)
(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)
trainAug = ImageDataGenerator(rotation_range=15, fill_mode="nearest")

"""VGG-16"""
baseModel = VGG16(weights="imagenet", include_top=False, input_tensor=Input(shape=(224,224,3)))
headModel = baseModel.output
headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(64, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(2, activation="softmax")(headModel)
vggmodel = Model(inputs=baseModel.input, outputs=headModel)
for layer in baseModel.layers:
  layer.trainable = False
vggmodel.summary()

#Using Adam optimizer
opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
vggmodel.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy","AUC"])

# train the head of the network
print("[INFO] training head...")
H = vggmodel.fit_generator(
  trainAug.flow(trainX, trainY, batch_size=BS),
  steps_per_epoch=len(trainX) // BS,
  validation_data=(testX, testY),
  validation_steps=len(testX) // BS,
  epochs=EPOCHS)

# plot the training loss and accuracy
N = EPOCHS
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), H.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, N), H.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy on COVID-19 Dataset")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
plt.savefig("plot.png")

#matrices
predIdxs = vggmodel.predict(testX, batch_size=BS)
predIdxs = np.argmax(predIdxs, axis=1)
cm = confusion_matrix(testY.argmax(axis=1), predIdxs)
total = sum(sum(cm))
acc = (cm[0, 0] + cm[1, 1]) / total
precision = cm[0, 0] / (cm[0, 0] + cm[0, 1])
recall = cm[1, 1] / (cm[1, 0] + cm[1, 1])
print(cm)
print("acc: {:.4f}".format(acc))
print("precision: {:.4f}".format(precision))
print("recall: {:.4f}".format(recall))

target_names = ['Normal','Covid-19']
from skimage import data, color, io, img_as_float
def get_heatmap(vgg_conv, processed_image, class_idx):
  eps=1e-8
  gradModel = Model(
    inputs=[vgg_conv.inputs],
    outputs=[vgg_conv.get_layer('block5_conv3').output, vgg_conv.output])
  with tf.GradientTape() as tape:
    inputs = tf.cast(processed_image, tf.float32)
    (convoutputs, predictions) = gradModel(inputs)
    loss = predictions[:, class_idx]
  # use automatic differentiation to compute the gradients
  grads = tape.gradient(loss, convoutputs)
  # compute the guided gradients
  castConvoutputs = tf.cast(convoutputs > 0, "float32")
  castGrads = tf.cast(grads > 0, "float32")
  guidedGrads = castConvoutputs * castGrads * grads
  convoutputs = convoutputs[0]
  guidedGrads = guidedGrads[0]
  weights = tf.reduce_mean(guidedGrads, axis=(0, 1))
  cam = tf.reduce_sum(tf.multiply(weights, convoutputs), axis=-1)
  (w, h) = (processed_image.shape[2], processed_image.shape[1])
  heatmap = cv2.resize(cam.numpy(), (w, h))
  numer = heatmap - np.min(heatmap)
  denom = (heatmap.max() - heatmap.min()) + eps
  heatmap = numer / denom
  heatmap = (heatmap * 255).astype("uint8")
  return heatmap

def print_GradCAM(base_model, path_image):
  # select the sample and read the corresponding image and label
  sample_image = cv2.imread(path_image)
  # pre-process the image
  sample_image = cv2.resize(sample_image, (224,224))
  if sample_image.shape[2] ==1:
    sample_image = np.dstack([sample_image, sample_image, sample_image])
  sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)
  sample_image = sample_image.astype(np.float32)/255.
  # sample_label = 1
  #since we pass only one image,we expand dim to include batch size 1
  sample_image_processed = np.expand_dims(sample_image, axis=0)
  # get the label predicted by our original model
  pred_label = np.argmax(base_model.predict(sample_image_processed), axis=-1)[0]
  # get the heatmap for class activation map(CAM)
  heatmap = get_heatmap(base_model, sample_image_processed, pred_label)
  heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))
  heatmap = heatmap *255
  heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)
  heatmap = 255 - heatmap
  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
  # f,ax = plt.subplots(1,2, figsize=(16,6))
  plt.figure()
  f, ax = plt.subplots(ncols=3, figsize=(16, 6))
  ax[1].imshow(heatmap)
  ax[1].set_title("heatmap")
  ax[1].axis('off')
  #superimpose the heatmap on the image 
  sample_image_hsv = color.rgb2hsv(sample_image)
  heatmap = color.rgb2hsv(heatmap)
  alpha=0.7
  sample_image_hsv[..., 0] = heatmap[..., 0]
  sample_image_hsv[..., 1] = heatmap[..., 1] * alpha
  img_masked = color.hsv2rgb(sample_image_hsv)
  # f,ax = plt.subplots(1,2, figsize=(16,6))
  ax[0].imshow(sample_image)
  ax[0].set_title(f"original image (predicted label: {target_names[pred_label]})")
  ax[0].axis('off')
  ax[2].imshow(img_masked)
  ax[2].set_title("superimposed image")
  ax[2].axis('off')
  plt.show()

outputPath ='../content/input/covid-chest-xray/images/16664_1_1.jpg'
print_GradCAM(vggmodel, outputPath)

outputPath = '../content/input/covid-chest-xray/images/covid-19-rapidly-progressive-acute-respiratory-distress-syndrome-ards-day-3.jpg'
print_GradCAM(vggmodel, outputPath)

covid_dataset_path='../content/input/covid-chest-xray'
csvPath = os.path.sep.join([covid_dataset_path, "metadata.csv"])
df = pd.read_csv(csvPath)
for (i, row) in df.iterrows():
  # if (1) the current case is not COVID-19 or (2) this is not
  # a 'PA' view, then ignore the row
  target_names = ['Covid-19','Normal']
  if row["finding"] == "COVID-19" or row["view"] != "PA" :
    continue
  imagePath = os.path.sep.join([covid_dataset_path, "images", row["filename"]])
  if not os.path.exists(imagePath):
    continue
  print_GradCAM(vggmodel, imagePath)

!pip install tf-explain

from tf_explain.core.activations import ExtractActivations
from tensorflow.keras.applications.densenet import DenseNet121
from tensorflow.keras.layers import BatchNormalization

baseModel = DenseNet121(input_shape = (224, 224, 3),include_top = False, weights = None)
headModel = baseModel.output
headModel=  BatchNormalization()(headModel)
headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(64, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(2, activation="softmax")(headModel)
dense_model = Model(inputs=baseModel.input, outputs=headModel)
for layer in baseModel.layers:
  layer.trainable = False
print(dense_model.summary())

#Using Adam optimizer
opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
dense_model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])

# train the head of the network
print("[INFO] training head...")
H = dense_model.fit_generator(
  trainAug.flow(trainX, trainY, batch_size=BS),
  steps_per_epoch=len(trainX) // BS,
  validation_data=(testX, testY),
  validation_steps=len(testX) // BS,
  epochs=EPOCHS)

# plot the training loss and accuracy
N = EPOCHS
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), H.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, N), H.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy on COVID-19 Dataset")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
plt.savefig("plot.png")

#matrices
predIdxs = dense_model.predict(testX, batch_size=BS)
predIdxs = np.argmax(predIdxs, axis=1)
cm = confusion_matrix(testY.argmax(axis=1), predIdxs)
total = sum(sum(cm))
acc = (cm[0, 0] + cm[1, 1]) / total
sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])
specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])
print(cm)
print("acc: {:.4f}".format(acc))
print("precision: {:.4f}".format(sensitivity))
print("recall: {:.4f}".format(specificity))

from skimage import data, color, io, img_as_float
def get_heatmap(vgg_conv, processed_image, class_idx):
  eps=1e-8
  gradModel = Model(
    inputs=[vgg_conv.inputs],
    outputs=[vgg_conv.get_layer('conv5_block16_2_conv').output, vgg_conv.output])
  with tf.GradientTape() as tape:
    inputs = tf.cast(processed_image, tf.float32)
    (convoutputs, predictions) = gradModel(inputs)
    loss = predictions[:, class_idx]
  # use automatic differentiation to compute the gradients
  grads = tape.gradient(loss, convoutputs)
  # compute the guided gradients
  castConvoutputs = tf.cast(convoutputs > 0, "float32")
  castGrads = tf.cast(grads > 0, "float32")
  guidedGrads = castConvoutputs * castGrads * grads
  convoutputs = convoutputs[0]
  guidedGrads = guidedGrads[0]
  weights = tf.reduce_mean(guidedGrads, axis=(0, 1))
  cam = tf.reduce_sum(tf.multiply(weights, convoutputs), axis=-1)
  (w, h) = (processed_image.shape[2], processed_image.shape[1])
  heatmap = cv2.resize(cam.numpy(), (w, h))
  numer = heatmap - np.min(heatmap)
  denom = (heatmap.max() - heatmap.min()) + eps
  heatmap = numer / denom
  heatmap = (heatmap * 255).astype("uint8")
  return heatmap

target_names = ['Normal','Covid-19']
outputPath = '../content/input/covid-chest-xray/images/16664_1_1.jpg'
print_GradCAM(dense_model, outputPath)

outputPath = '../content/input/covid-chest-xray/images/covid-19-rapidly-progressive-acute-respiratory-distress-syndrome-ards-day-3.jpg'
print_GradCAM(dense_model, outputPath)

from tf_explain.core.activations import ExtractActivations
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import BatchNormalization

baseModel = ResNet50(input_shape = (224, 224, 3), 
  include_top = False, weights = None)
headModel = baseModel.output
headModel=BatchNormalization()(headModel)
headModel = AveragePooling2D(pool_size=(4, 4))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(64, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(2, activation="softmax")(headModel)
resnet = Model(inputs=baseModel.input, outputs=headModel)
for layer in baseModel.layers:
  layer.trainable = False
print(resnet.summary())

#Using Adam optimizer
opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
resnet.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])

# train the head of the network
print("[INFO] training head...")
H = resnet.fit_generator(
  trainAug.flow(trainX, trainY, batch_size=BS),
  steps_per_epoch=len(trainX) // BS,
  validation_data=(testX, testY),
  validation_steps=len(testX) // BS,
  epochs=EPOCHS)

# plot the training loss and accuracy
N = EPOCHS
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), H.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, N), H.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy on COVID-19 Dataset")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
plt.savefig("plot.png")

#matrices
predIdxs = resnet.predict(testX, batch_size=BS)
predIdxs = np.argmax(predIdxs, axis=1)
cm = confusion_matrix(testY.argmax(axis=1), predIdxs)
total = sum(sum(cm))
acc = (cm[0, 0] + cm[1, 1]) / total
sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])
specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])
print(cm)
print("acc: {:.4f}".format(acc))
print("precision: {:.4f}".format(sensitivity))
print("recall: {:.4f}".format(specificity))

from skimage import data, color, io, img_as_float
def get_heatmap(vgg_conv, processed_image, class_idx):
  eps=1e-8
  gradModel = Model(
    inputs=[vgg_conv.inputs],
    outputs=[vgg_conv.get_layer('conv5_block3_3_conv').output, vgg_conv.output])
  with tf.GradientTape() as tape:
    inputs = tf.cast(processed_image, tf.float32)
    (convoutputs, predictions) = gradModel(inputs)
    loss = predictions[:, class_idx]
  # use automatic differentiation to compute the gradients
  grads = tape.gradient(loss, convoutputs)
  # compute the guided gradients
  castConvoutputs = tf.cast(convoutputs > 0, "float32")
  castGrads = tf.cast(grads > 0, "float32")
  guidedGrads = castConvoutputs * castGrads * grads
  convoutputs = convoutputs[0]
  guidedGrads = guidedGrads[0]
  weights = tf.reduce_mean(guidedGrads, axis=(0, 1))
  cam = tf.reduce_sum(tf.multiply(weights, convoutputs), axis=-1)
  (w, h) = (processed_image.shape[2], processed_image.shape[1])
  heatmap = cv2.resize(cam.numpy(), (w, h))
  numer = heatmap - np.min(heatmap)
  denom = (heatmap.max() - heatmap.min()) + eps
  heatmap = numer / denom
  heatmap = (heatmap * 255).astype("uint8")
  return heatmap

outputPath = '../content/input/covid-chest-xray/images/16664_1_1.jpg'
print_GradCAM(resnet, outputPath)
outputPath = '../content/input/covid-chest-xray/images/covid-19-rapidly-progressive-acute-respiratory-distress-syndrome-ards-day-3.jpg'
print_GradCAM(resnet, outputPath)